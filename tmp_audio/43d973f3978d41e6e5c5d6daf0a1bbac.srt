1
00:00:00,140 --> 00:00:06,079
Speaker 0: Hi, I'm happy to be back with Sharon Zhou, the instructor for this course, Fine-tuning Large Language Models.

2
00:00:06,560 --> 00:00:08,299
Speaker 1: Hi Andrew, super excited to be back.

3
00:00:08,882 --> 00:01:03,799
Speaker 0: As you may know, Sharon had also previously taught deeplearning.ai's short course on diffusion models, as well as the GAN specialization hosted on Coursera. In this course, Sharon will be diving into fine-tuning OMs, that is, large language models. Broadly, there are three ways that application developers are using OMs. First is prompting, which is really fast and can get you pretty good results. For example, you can write a prompt to tell an LM to classify a piece of text as positive or negative sentiment and have that up and running in minutes. The other extreme is training, or sometimes we say pre-training, a large foundation model from scratch. That can cost tens of millions of dollars and require hundreds of billions or more words to train on. Most people outside well-resourced companies might have a hard time doing that. Finally, there's an important design point in between, which is to fine-tune an open-source language model.

4
00:01:04,160 --> 00:01:23,080
Speaker 1: You can take an LLM and fine-tune it on only 100 examples, 1,000, or even 10,000 examples. And this takes minutes to hours, rather than seconds with prompting or months with pre-training. But this can also get you a significantly higher level of performance on your specific use case than either of the other approaches.

5
00:01:23,660 --> 00:01:43,179
Speaker 0: The world has quickly adapted to the powerful capabilities that LLMs like ChatGPT have made possible. But if you can't make good use of your own domain-specific or proprietary data, you can start to run into the limitations of the general-purpose LLMs. With fine-tuning, you can specialize an LLM to your own data.

6
00:01:43,660 --> 00:02:14,459
Speaker 1: So in this course, you'll learn all about, one, how fine-tuning fits into training, two, how it differs from prompt engineering or retrieval augmented generation alone, and three, you'll dive into a specific variant called instruction fine-tuning that teaches an LLM to follow instructions similar to ChatGPT. And you'll go through all of these steps in code. Then you'll come away from the course with a concrete understanding of fine-tuning LLMs and be able to get started using these techniques for your own projects.

7
00:02:15,100 --> 00:02:31,100
Speaker 0: So lots of cool things in this short course. And I think fine-tuning is a significant step up in capability compared to just prompting. And it is an important tool for people building applications using LLMs to know. So I hope you enjoy the course.

